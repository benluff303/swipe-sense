{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65f0cb-87f0-44f7-85b8-6da1305f8a29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import torch\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load CLIP model\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\", use_safetensors=True)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# 2. Init GCS client + bucket\n",
    "client = storage.Client()\n",
    "bucket_name = \"swipe-bucket\"\n",
    "bucket = client.bucket(bucket_name)\n",
    "\n",
    "# 3. Candidate labels\n",
    "labels = [\"a photo of nature\", \"a photo of a city\", \"an abstract photo\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "# 4. Loop through ALL images in bucket\n",
    "for blob in bucket.list_blobs():\n",
    "    if not blob.name.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    img_bytes = blob.download_as_bytes()\n",
    "    image = Image.open(BytesIO(img_bytes)).convert(\"RGB\")\n",
    "\n",
    "    # Run through CLIP\n",
    "    inputs = processor(text=labels, images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    probs = outputs.logits_per_image.softmax(dim=1)[0].tolist()\n",
    "\n",
    "    # Get top prediction\n",
    "    top_idx = torch.argmax(torch.tensor(probs)).item()\n",
    "    predicted_type = labels[top_idx].replace(\"a photo of \", \"\").replace(\"an \", \"\")\n",
    "\n",
    "    # Build public URL\n",
    "    image_url = f\"https://storage.googleapis.com/{bucket_name}/{blob.name}\"\n",
    "\n",
    "    results.append({\n",
    "        \"image_id\": f\"<a href='{image_url}' target='_blank'>{blob.name}</a>\",\n",
    "        \"predicted_type\": predicted_type\n",
    "    })\n",
    "\n",
    "# 5. Build DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# 6. Drop all abstract images\n",
    "filtered_df = df[df[\"predicted_type\"] != \"abstract\"]\n",
    "\n",
    "# 7. Save HTML with clickable links\n",
    "filtered_df.to_html(\"filtered_images.html\", escape=False, index=False)\n",
    "\n",
    "# 8. Upload HTML back to GCS\n",
    "out_blob = bucket.blob(\"outputs/filtered_images.html\")\n",
    "out_blob.upload_from_filename(\"filtered_images.html\")\n",
    "\n",
    "print(\"Clickable filtered results uploaded to:\")\n",
    "print(f\"https://storage.googleapis.com/{bucket_name}/outputs/filtered_images.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0f1c8-66ab-49e8-8e2f-639eb4e0158f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
